{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from multiprocessing import Pool, cpu_count\n",
    "import time\n",
    "from typing import List, Dict, Optional\n",
    "import logging\n",
    "from urllib.parse import urlparse\n",
    "from geocode.geocode import Geocode\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO, format=\"%(asctime)s - %(levelname)s - %(message)s\"\n",
    ")\n",
    "\n",
    "\n",
    "def scrape_about_page(url: str) -> Optional[Dict]:\n",
    "    \"\"\"\n",
    "    Scrapes an about page and extracts its main content.\n",
    "\n",
    "    Args:\n",
    "        url: The URL of the about page to scrape\n",
    "\n",
    "    Returns:\n",
    "        Dictionary containing the URL and extracted text, or None if failed\n",
    "    \"\"\"\n",
    "    try:\n",
    "        headers = {\n",
    "            \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36\"\n",
    "        }\n",
    "\n",
    "        response = requests.get(url, headers=headers, timeout=10)\n",
    "        response.raise_for_status()\n",
    "\n",
    "        soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "\n",
    "        # Remove script and style elements\n",
    "        for element in soup([\"script\", \"style\", \"nav\", \"header\", \"footer\"]):\n",
    "            element.decompose()\n",
    "\n",
    "        # Extract main content - looking for common content containers\n",
    "        content = None\n",
    "        for selector in [\"main\", \"article\", \".content\", \"#content\", \".about\", \"#about\"]:\n",
    "            content = soup.select_one(selector)\n",
    "            if content:\n",
    "                break\n",
    "\n",
    "        # If no main content found, use body\n",
    "        if not content:\n",
    "            content = soup.body\n",
    "\n",
    "        if content:\n",
    "            text = \" \".join(content.stripped_strings)\n",
    "            return {\"url\": url, \"text\": text, \"domain\": urlparse(url).netloc}\n",
    "        return None\n",
    "\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error scraping {url}: {str(e)}\")\n",
    "        return None\n",
    "\n",
    "\n",
    "def parallel_scrape(urls: List[str], num_processes: Optional[int] = None) -> List[Dict]:\n",
    "    \"\"\"\n",
    "    Scrapes multiple URLs in parallel using multiprocessing.\n",
    "\n",
    "    Args:\n",
    "        urls: List of URLs to scrape\n",
    "        num_processes: Number of processes to use (defaults to CPU count)\n",
    "\n",
    "    Returns:\n",
    "        List of dictionaries containing scraped data\n",
    "    \"\"\"\n",
    "    if num_processes is None:\n",
    "        num_processes = cpu_count()\n",
    "\n",
    "    logging.info(f\"Starting parallel scraping with {num_processes} processes\")\n",
    "    start_time = time.time()\n",
    "\n",
    "    with Pool(num_processes) as pool:\n",
    "        results = pool.map(scrape_about_page, urls)\n",
    "\n",
    "    # Filter out None results from failed scrapes\n",
    "    valid_results = [r for r in results if r is not None]\n",
    "\n",
    "    elapsed_time = time.time() - start_time\n",
    "    logging.info(f\"Scraped {len(valid_results)} pages in {elapsed_time:.2f} seconds\")\n",
    "\n",
    "    return valid_results\n",
    "\n",
    "\n",
    "def process_locations(\n",
    "    scraped_data: List[Dict], num_cpus: Optional[int] = None\n",
    ") -> List[Dict]:\n",
    "    \"\"\"\n",
    "    Processes scraped text to extract location information using parallel processing.\n",
    "    This should be run after scraping due to memory requirements.\n",
    "\n",
    "    Args:\n",
    "        scraped_data: List of dictionaries containing scraped text\n",
    "        num_cpus: Number of CPU cores to use for parallel processing (defaults to all available)\n",
    "\n",
    "    Returns:\n",
    "        List of dictionaries with location information added\n",
    "    \"\"\"\n",
    "    gc = Geocode()\n",
    "    gc.load()  # load geonames data\n",
    "\n",
    "    # Extract text content for parallel processing\n",
    "    texts = [item[\"text\"] for item in scraped_data]\n",
    "\n",
    "    try:\n",
    "        # Process locations in parallel\n",
    "        all_locations = gc.decode_parallel(texts, num_cpus=num_cpus)\n",
    "\n",
    "        # Merge results back with original data\n",
    "        results = []\n",
    "        for item, locations in zip(scraped_data, all_locations):\n",
    "            item[\"locations\"] = locations\n",
    "            results.append(item)\n",
    "\n",
    "        return results\n",
    "\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error in parallel location processing: {str(e)}\")\n",
    "        raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as pl\n",
    "\n",
    "urls = pl.read_parquet(\"../data/output/about_pages.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "about_page = scrape_about_page(urls.select(pl.col(\"url\").first()).item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flair.data import Sentence\n",
    "from flair.models import SequenceTagger\n",
    "\n",
    "# load tagger\n",
    "tagger = SequenceTagger.load(\"flair/ner-english-fast\")\n",
    "\n",
    "sentences = [Sentence(sentence) for sentence in about_page[\"text\"].split(\".\")]\n",
    "# make example sentence\n",
    "\n",
    "# predict NER tags\n",
    "tagger.predict(sentences)\n",
    "\n",
    "# print sentence\n",
    "\n",
    "# print predicted NER spans\n",
    "print(\"The following NER tags are found:\")\n",
    "# iterate over entities and print\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(urls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence.get_spans(\"ner\")[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy \n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "# Access the entity recognizer (NER) pipe\n",
    "ner = nlp.get_pipe(\"ner\")\n",
    "\n",
    "# Get the raw entity predictions for the document\n",
    "doc = nlp(about_page[\"text\"])\n",
    "beams = ner.predict([doc])\n",
    "\n",
    "# Get entity labels\n",
    "entity_labels = ner.labels\n",
    "\n",
    "# Process the beam outputs\n",
    "for doc_idx, beam in enumerate(beams):\n",
    "    for i, (score, ents) in enumerate(beam):\n",
    "        if i == 0:  # Only look at the top-scoring analysis\n",
    "            print(f\"Document score: {score:.4f}\")\n",
    "\n",
    "            # Group spans by tokens\n",
    "            token_to_ents = {}\n",
    "            for start, end, label_id in ents:\n",
    "                entity_label = entity_labels[label_id]\n",
    "                entity_text = doc[start:end].text\n",
    "                entity_score = score  # This is the overall beam score\n",
    "\n",
    "                print(\n",
    "                    f\"Entity: {entity_text}, Label: {entity_label}, Score: {entity_score:.4f}\"\n",
    "                )\n",
    "                print(f\"  Position: {start} to {end}\")\n",
    "\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recognized entities:\n",
      "Entity: Privacy Statement and Cookie, Label: ORG, Span: (40, 44)\n",
      "Entity: Graduate Degrees MA, Label: PERSON, Span: (55, 58)\n",
      "Entity: Philosophy Ethics and Public Affairs, Label: ORG, Span: (59, 64)\n",
      "Entity: Degrees BA, Label: PERSON, Span: (70, 72)\n",
      "Entity: Philosophy Philosophy, Label: ORG, Span: (73, 75)\n",
      "Entity: Economics, Label: ORG, Span: (83, 84)\n",
      "Entity: Ethics, Label: GPE, Span: (87, 88)\n",
      "Entity: Law Minor, Label: PERSON, Span: (97, 99)\n",
      "Entity: Philosophy for Social Change Courses People Careers News Headlines In The Media Publications Events All Upcoming Past Events Events, Label: ORG, Span: (104, 123)\n",
      "Entity: Graduate Degrees MA, Label: PERSON, Span: (128, 131)\n",
      "Entity: Philosophy Ethics and Public Affairs, Label: ORG, Span: (132, 137)\n",
      "Entity: Degrees BA, Label: PERSON, Span: (143, 145)\n",
      "Entity: Philosophy Philosophy, Label: ORG, Span: (146, 148)\n",
      "Entity: Economics, Label: ORG, Span: (156, 157)\n",
      "Entity: Ethics, Label: GPE, Span: (160, 161)\n",
      "Entity: Law Minor, Label: PERSON, Span: (170, 172)\n",
      "Entity: Philosophy for Social Change Courses People Careers News Events Give Apply Contact Us, Label: ORG, Span: (177, 190)\n",
      "Entity: Alumni Undergraduate Students Academic Advising Honors, Label: ORG, Span: (213, 219)\n",
      "Entity: Phil) Club Internship Standards of Good Writing, Label: ORG, Span: (223, 231)\n",
      "Entity: Alumni Undergraduate Students Academic Advising Honors, Label: ORG, Span: (260, 266)\n",
      "Entity: Phil) Club Internship Standards of Good Writing, Label: ORG, Span: (270, 278)\n",
      "Entity: Western, Label: NORP, Span: (368, 369)\n",
      "Entity: Katrina Sifferd, Label: PERSON, Span: (470, 472)\n",
      "Entity: the Graduate Record Exam, Label: FAC, Span: (538, 542)\n",
      "Entity: GRE, Label: ORG, Span: (543, 544)\n",
      "Entity: GMAT’s, Label: ORG, Span: (559, 561)\n",
      "Entity: MCAT, Label: ORG, Span: (563, 564)\n",
      "Entity: George Mason, Label: PERSON, Span: (570, 572)\n",
      "Entity: The George Mason Department of Philosophy, Label: ORG, Span: (573, 579)\n",
      "Entity: Continental, Label: ORG, Span: (609, 610)\n",
      "Entity: Junior-, Label: PERSON, Span: (623, 624)\n",
      "Entity: fewer than 35, Label: CARDINAL, Span: (641, 644)\n",
      "Entity: Major Philosophy 4400, Label: ORG, Span: (702, 705)\n",
      "Entity: University Drive, Label: PERSON, Span: (705, 707)\n",
      "Entity: 3F1, Label: CARDINAL, Span: (708, 709)\n",
      "Entity: Fairfax, Label: GPE, Span: (709, 710)\n",
      "Entity: VA 22030 Contact, Label: ORG, Span: (711, 714)\n",
      "Entity: Horizon Hall, Label: FAC, Span: (715, 717)\n",
      "Entity: +1-703, Label: NORP, Span: (720, 723)\n",
      "Entity: 2025, Label: DATE, Span: (744, 745)\n",
      "Entity: George Mason University, Label: ORG, Span: (745, 748)\n",
      "\n",
      "Available NER methods:\n",
      "TransitionSystem\n",
      "add_label\n",
      "add_multitask_objective\n",
      "beam_parse\n",
      "cfg\n",
      "create_optimizer\n",
      "finish_update\n",
      "from_bytes\n",
      "from_disk\n",
      "get_batch_loss\n",
      "get_error_handler\n",
      "get_loss\n",
      "greedy_parse\n",
      "hide_labels\n",
      "incorrect_spans_key\n",
      "init_multitask_objectives\n",
      "initialize\n",
      "is_resizable\n",
      "is_trainable\n",
      "label_data\n",
      "labels\n",
      "model\n",
      "move_names\n",
      "moves\n",
      "name\n",
      "pipe\n",
      "postprocesses\n",
      "predict\n",
      "rehearse\n",
      "score\n",
      "scored_ents\n",
      "scorer\n",
      "set_annotations\n",
      "set_error_handler\n",
      "set_output\n",
      "to_bytes\n",
      "to_disk\n",
      "tok2vec\n",
      "transition_states\n",
      "update\n",
      "update_beam\n",
      "use_params\n",
      "vocab\n",
      "\n",
      "NER scores type: <class 'list'>\n",
      "NER scores structure: [<spacy.pipeline._parser_internals.stateclass.StateClass object at 0x303de11c0>]\n",
      "\n",
      "Token-level entity information:\n",
      "Token: We, IOB: O-\n",
      "Token: use, IOB: O-\n",
      "Token: cookies, IOB: O-\n",
      "Token: and, IOB: O-\n",
      "Token: similar, IOB: O-\n",
      "Token: technologies, IOB: O-\n",
      "Token: to, IOB: O-\n",
      "Token: improve, IOB: O-\n",
      "Token: your, IOB: O-\n",
      "Token: website, IOB: O-\n",
      "Token: experience, IOB: O-\n",
      "Token: and, IOB: O-\n",
      "Token: help, IOB: O-\n",
      "Token: us, IOB: O-\n",
      "Token: understand, IOB: O-\n",
      "Token: how, IOB: O-\n",
      "Token: you, IOB: O-\n",
      "Token: use, IOB: O-\n",
      "Token: our, IOB: O-\n",
      "Token: website, IOB: O-\n",
      "Token: ., IOB: O-\n",
      "Token: By, IOB: O-\n",
      "Token: continuing, IOB: O-\n",
      "Token: to, IOB: O-\n",
      "Token: use, IOB: O-\n",
      "Token: this, IOB: O-\n",
      "Token: website, IOB: O-\n",
      "Token: ,, IOB: O-\n",
      "Token: you, IOB: O-\n",
      "Token: consent, IOB: O-\n",
      "Token: to, IOB: O-\n",
      "Token: the, IOB: O-\n",
      "Token: usage, IOB: O-\n",
      "Token: of, IOB: O-\n",
      "Token: cookies, IOB: O-\n",
      "Token: ., IOB: O-\n",
      "Token: Learn, IOB: O-\n",
      "Token: more, IOB: O-\n",
      "Token: about, IOB: O-\n",
      "Token: our, IOB: O-\n",
      "Token: Privacy, IOB: B-ORG\n",
      "Token: Statement, IOB: I-ORG\n",
      "Token: and, IOB: I-ORG\n",
      "Token: Cookie, IOB: I-ORG\n",
      "Token: Policy, IOB: O-\n",
      "Token: ., IOB: O-\n",
      "Token: Agree, IOB: O-\n",
      "Token: Decline, IOB: O-\n",
      "Token: Non, IOB: O-\n",
      "Token: -, IOB: O-\n",
      "Token: Essential, IOB: O-\n",
      "Token: Cookies, IOB: O-\n",
      "Token: ×, IOB: O-\n",
      "Token: About, IOB: O-\n",
      "Token: Philosophy, IOB: O-\n",
      "Token: Graduate, IOB: B-PERSON\n",
      "Token: Degrees, IOB: I-PERSON\n",
      "Token: MA, IOB: I-PERSON\n",
      "Token: in, IOB: O-\n",
      "Token: Philosophy, IOB: B-ORG\n",
      "Token: Ethics, IOB: I-ORG\n",
      "Token: and, IOB: I-ORG\n",
      "Token: Public, IOB: I-ORG\n",
      "Token: Affairs, IOB: I-ORG\n",
      "Token: concentration, IOB: O-\n",
      "Token: Accelerated, IOB: O-\n",
      "Token: MA, IOB: O-\n",
      "Token: in, IOB: O-\n",
      "Token: Philosophy, IOB: O-\n",
      "Token: Undergraduate, IOB: O-\n",
      "Token: Degrees, IOB: B-PERSON\n",
      "Token: BA, IOB: I-PERSON\n",
      "Token: in, IOB: O-\n",
      "Token: Philosophy, IOB: B-ORG\n",
      "Token: Philosophy, IOB: I-ORG\n",
      "Token: and, IOB: O-\n",
      "Token: Law, IOB: O-\n",
      "Token: concentration, IOB: O-\n",
      "Token: Philosophy, IOB: O-\n",
      "Token: ,, IOB: O-\n",
      "Token: Politics, IOB: O-\n",
      "Token: ,, IOB: O-\n",
      "Token: and, IOB: O-\n",
      "Token: Economics, IOB: B-ORG\n",
      "Token: concentration, IOB: O-\n",
      "Token: Minor, IOB: O-\n",
      "Token: in, IOB: O-\n",
      "Token: Ethics, IOB: B-GPE\n",
      "Token: and, IOB: O-\n",
      "Token: AI, IOB: O-\n",
      "Token: Minor, IOB: O-\n",
      "Token: in, IOB: O-\n",
      "Token: Philosophy, IOB: O-\n",
      "Token: Minor, IOB: O-\n",
      "Token: in, IOB: O-\n",
      "Token: Philosophy, IOB: O-\n",
      "Token: and, IOB: O-\n",
      "Token: Law, IOB: B-PERSON\n",
      "Token: Minor, IOB: I-PERSON\n",
      "Token: in, IOB: O-\n",
      "Token: Political, IOB: O-\n",
      "Token: Philosophy, IOB: O-\n",
      "Token: Minor, IOB: O-\n",
      "Token: in, IOB: O-\n",
      "Token: Philosophy, IOB: B-ORG\n",
      "Token: for, IOB: I-ORG\n",
      "Token: Social, IOB: I-ORG\n",
      "Token: Change, IOB: I-ORG\n",
      "Token: Courses, IOB: I-ORG\n",
      "Token: People, IOB: I-ORG\n",
      "Token: Careers, IOB: I-ORG\n",
      "Token: News, IOB: I-ORG\n",
      "Token: Headlines, IOB: I-ORG\n",
      "Token: In, IOB: I-ORG\n",
      "Token: The, IOB: I-ORG\n",
      "Token: Media, IOB: I-ORG\n",
      "Token: Publications, IOB: I-ORG\n",
      "Token: Events, IOB: I-ORG\n",
      "Token: All, IOB: I-ORG\n",
      "Token: Upcoming, IOB: I-ORG\n",
      "Token: Past, IOB: I-ORG\n",
      "Token: Events, IOB: I-ORG\n",
      "Token: Events, IOB: I-ORG\n",
      "Token: on, IOB: O-\n",
      "Token: Other, IOB: O-\n",
      "Token: Sites, IOB: O-\n",
      "Token: About, IOB: O-\n",
      "Token: Philosophy, IOB: O-\n",
      "Token: Graduate, IOB: B-PERSON\n",
      "Token: Degrees, IOB: I-PERSON\n",
      "Token: MA, IOB: I-PERSON\n",
      "Token: in, IOB: O-\n",
      "Token: Philosophy, IOB: B-ORG\n",
      "Token: Ethics, IOB: I-ORG\n",
      "Token: and, IOB: I-ORG\n",
      "Token: Public, IOB: I-ORG\n",
      "Token: Affairs, IOB: I-ORG\n",
      "Token: concentration, IOB: O-\n",
      "Token: Accelerated, IOB: O-\n",
      "Token: MA, IOB: O-\n",
      "Token: in, IOB: O-\n",
      "Token: Philosophy, IOB: O-\n",
      "Token: Undergraduate, IOB: O-\n",
      "Token: Degrees, IOB: B-PERSON\n",
      "Token: BA, IOB: I-PERSON\n",
      "Token: in, IOB: O-\n",
      "Token: Philosophy, IOB: B-ORG\n",
      "Token: Philosophy, IOB: I-ORG\n",
      "Token: and, IOB: O-\n",
      "Token: Law, IOB: O-\n",
      "Token: concentration, IOB: O-\n",
      "Token: Philosophy, IOB: O-\n",
      "Token: ,, IOB: O-\n",
      "Token: Politics, IOB: O-\n",
      "Token: ,, IOB: O-\n",
      "Token: and, IOB: O-\n",
      "Token: Economics, IOB: B-ORG\n",
      "Token: concentration, IOB: O-\n",
      "Token: Minor, IOB: O-\n",
      "Token: in, IOB: O-\n",
      "Token: Ethics, IOB: B-GPE\n",
      "Token: and, IOB: O-\n",
      "Token: AI, IOB: O-\n",
      "Token: Minor, IOB: O-\n",
      "Token: in, IOB: O-\n",
      "Token: Philosophy, IOB: O-\n",
      "Token: Minor, IOB: O-\n",
      "Token: in, IOB: O-\n",
      "Token: Philosophy, IOB: O-\n",
      "Token: and, IOB: O-\n",
      "Token: Law, IOB: B-PERSON\n",
      "Token: Minor, IOB: I-PERSON\n",
      "Token: in, IOB: O-\n",
      "Token: Political, IOB: O-\n",
      "Token: Philosophy, IOB: O-\n",
      "Token: Minor, IOB: O-\n",
      "Token: in, IOB: O-\n",
      "Token: Philosophy, IOB: B-ORG\n",
      "Token: for, IOB: I-ORG\n",
      "Token: Social, IOB: I-ORG\n",
      "Token: Change, IOB: I-ORG\n",
      "Token: Courses, IOB: I-ORG\n",
      "Token: People, IOB: I-ORG\n",
      "Token: Careers, IOB: I-ORG\n",
      "Token: News, IOB: I-ORG\n",
      "Token: Events, IOB: I-ORG\n",
      "Token: Give, IOB: I-ORG\n",
      "Token: Apply, IOB: I-ORG\n",
      "Token: Contact, IOB: I-ORG\n",
      "Token: Us, IOB: I-ORG\n",
      "Token: Graduate, IOB: O-\n",
      "Token: Students, IOB: O-\n",
      "Token: Guidelines, IOB: O-\n",
      "Token: for, IOB: O-\n",
      "Token: Master, IOB: O-\n",
      "Token: 's, IOB: O-\n",
      "Token: Proposals, IOB: O-\n",
      "Token: and, IOB: O-\n",
      "Token: Theses, IOB: O-\n",
      "Token: So, IOB: O-\n",
      "Token: ,, IOB: O-\n",
      "Token: What, IOB: O-\n",
      "Token: Are, IOB: O-\n",
      "Token: You, IOB: O-\n",
      "Token: Going, IOB: O-\n",
      "Token: to, IOB: O-\n",
      "Token: Do, IOB: O-\n",
      "Token: With, IOB: O-\n",
      "Token: That, IOB: O-\n",
      "Token: Degree, IOB: O-\n",
      "Token: ?, IOB: O-\n",
      "Token: Answers, IOB: O-\n",
      "Token: from, IOB: O-\n",
      "Token: Alumni, IOB: B-ORG\n",
      "Token: Undergraduate, IOB: I-ORG\n",
      "Token: Students, IOB: I-ORG\n",
      "Token: Academic, IOB: I-ORG\n",
      "Token: Advising, IOB: I-ORG\n",
      "Token: Honors, IOB: I-ORG\n",
      "Token: in, IOB: O-\n",
      "Token: Philosophy, IOB: O-\n",
      "Token: Philosophy, IOB: O-\n",
      "Token: (, IOB: O-\n",
      "Token: Phil, IOB: B-ORG\n",
      "Token: ), IOB: I-ORG\n",
      "Token: Club, IOB: I-ORG\n",
      "Token: Internship, IOB: I-ORG\n",
      "Token: Standards, IOB: I-ORG\n",
      "Token: of, IOB: I-ORG\n",
      "Token: Good, IOB: I-ORG\n",
      "Token: Writing, IOB: I-ORG\n",
      "Token: in, IOB: O-\n",
      "Token: Philosophy, IOB: O-\n",
      "Token: Career, IOB: O-\n",
      "Token: pathways, IOB: O-\n",
      "Token: Prospective, IOB: O-\n",
      "Token: Students, IOB: O-\n",
      "Token: Graduate, IOB: O-\n",
      "Token: Students, IOB: O-\n",
      "Token: Guidelines, IOB: O-\n",
      "Token: for, IOB: O-\n",
      "Token: Master, IOB: O-\n",
      "Token: 's, IOB: O-\n",
      "Token: Proposals, IOB: O-\n",
      "Token: and, IOB: O-\n",
      "Token: Theses, IOB: O-\n",
      "Token: So, IOB: O-\n",
      "Token: ,, IOB: O-\n",
      "Token: What, IOB: O-\n",
      "Token: Are, IOB: O-\n",
      "Token: You, IOB: O-\n",
      "Token: Going, IOB: O-\n",
      "Token: to, IOB: O-\n",
      "Token: Do, IOB: O-\n",
      "Token: With, IOB: O-\n",
      "Token: That, IOB: O-\n",
      "Token: Degree, IOB: O-\n",
      "Token: ?, IOB: O-\n",
      "Token: Answers, IOB: O-\n",
      "Token: from, IOB: O-\n",
      "Token: Alumni, IOB: B-ORG\n",
      "Token: Undergraduate, IOB: I-ORG\n",
      "Token: Students, IOB: I-ORG\n",
      "Token: Academic, IOB: I-ORG\n",
      "Token: Advising, IOB: I-ORG\n",
      "Token: Honors, IOB: I-ORG\n",
      "Token: in, IOB: O-\n",
      "Token: Philosophy, IOB: O-\n",
      "Token: Philosophy, IOB: O-\n",
      "Token: (, IOB: O-\n",
      "Token: Phil, IOB: B-ORG\n",
      "Token: ), IOB: I-ORG\n",
      "Token: Club, IOB: I-ORG\n",
      "Token: Internship, IOB: I-ORG\n",
      "Token: Standards, IOB: I-ORG\n",
      "Token: of, IOB: I-ORG\n",
      "Token: Good, IOB: I-ORG\n",
      "Token: Writing, IOB: I-ORG\n",
      "Token: in, IOB: O-\n",
      "Token: Philosophy, IOB: O-\n",
      "Token: Career, IOB: O-\n",
      "Token: pathways, IOB: O-\n",
      "Token: Prospective, IOB: O-\n",
      "Token: Students, IOB: O-\n",
      "Token: Give, IOB: O-\n",
      "Token: Apply, IOB: O-\n",
      "Token: Contact, IOB: O-\n",
      "Token: Us, IOB: O-\n",
      "Token: About, IOB: O-\n",
      "Token: Philosophy, IOB: O-\n",
      "Token: Why, IOB: O-\n",
      "Token: Study, IOB: O-\n",
      "Token: Philosophy, IOB: O-\n",
      "Token: ?, IOB: O-\n",
      "Token: Be, IOB: O-\n",
      "Token: Employable, IOB: O-\n",
      "Token: ,, IOB: O-\n",
      "Token: Study, IOB: O-\n",
      "Token: Philosophy, IOB: O-\n",
      "Token: Reasons, IOB: O-\n",
      "Token: to, IOB: O-\n",
      "Token: Study, IOB: O-\n",
      "Token: Philosophy, IOB: O-\n",
      "Token: Still, IOB: O-\n",
      "Token: More, IOB: O-\n",
      "Token: Reasons, IOB: O-\n",
      "Token: to, IOB: O-\n",
      "Token: Study, IOB: O-\n",
      "Token: Philosophy, IOB: O-\n",
      "Token: The, IOB: O-\n",
      "Token: Earning, IOB: O-\n",
      "Token: Power, IOB: O-\n",
      "Token: of, IOB: O-\n",
      "Token: Philosophy, IOB: O-\n",
      "Token: Majors, IOB: O-\n",
      "Token: Salary, IOB: O-\n",
      "Token: Increase, IOB: O-\n",
      "Token: by, IOB: O-\n",
      "Token: Major, IOB: O-\n",
      "Token: Philosophy, IOB: O-\n",
      "Token: is, IOB: O-\n",
      "Token: concerned, IOB: O-\n",
      "Token: with, IOB: O-\n",
      "Token: the, IOB: O-\n",
      "Token: basic, IOB: O-\n",
      "Token: questions, IOB: O-\n",
      "Token: of, IOB: O-\n",
      "Token: human, IOB: O-\n",
      "Token: existence, IOB: O-\n",
      "Token: :, IOB: O-\n",
      "Token: How, IOB: O-\n",
      "Token: should, IOB: O-\n",
      "Token: I, IOB: O-\n",
      "Token: live, IOB: O-\n",
      "Token: ?, IOB: O-\n",
      "Token: What, IOB: O-\n",
      "Token: is, IOB: O-\n",
      "Token: a, IOB: O-\n",
      "Token: just, IOB: O-\n",
      "Token: society, IOB: O-\n",
      "Token: ?, IOB: O-\n",
      "Token: What, IOB: O-\n",
      "Token: is, IOB: O-\n",
      "Token: knowledge, IOB: O-\n",
      "Token: ?, IOB: O-\n",
      "Token: What, IOB: O-\n",
      "Token: is, IOB: O-\n",
      "Token: beauty, IOB: O-\n",
      "Token: ?, IOB: O-\n",
      "Token: Is, IOB: O-\n",
      "Token: there, IOB: O-\n",
      "Token: a, IOB: O-\n",
      "Token: God, IOB: O-\n",
      "Token: ?, IOB: O-\n",
      "Token: Through, IOB: O-\n",
      "Token: the, IOB: O-\n",
      "Token: study, IOB: O-\n",
      "Token: of, IOB: O-\n",
      "Token: philosophy, IOB: O-\n",
      "Token: ,, IOB: O-\n",
      "Token: students, IOB: O-\n",
      "Token: become, IOB: O-\n",
      "Token: familiar, IOB: O-\n",
      "Token: with, IOB: O-\n",
      "Token: the, IOB: O-\n",
      "Token: long, IOB: O-\n",
      "Token: tradition, IOB: O-\n",
      "Token: of, IOB: O-\n",
      "Token: Western, IOB: B-NORP\n",
      "Token: thought, IOB: O-\n",
      "Token: on, IOB: O-\n",
      "Token: these, IOB: O-\n",
      "Token: issues, IOB: O-\n",
      "Token: ., IOB: O-\n",
      "Token: They, IOB: O-\n",
      "Token: learn, IOB: O-\n",
      "Token: about, IOB: O-\n",
      "Token: the, IOB: O-\n",
      "Token: efforts, IOB: O-\n",
      "Token: of, IOB: O-\n",
      "Token: contemporary, IOB: O-\n",
      "Token: philosophers, IOB: O-\n",
      "Token: to, IOB: O-\n",
      "Token: answer, IOB: O-\n",
      "Token: these, IOB: O-\n",
      "Token: questions, IOB: O-\n",
      "Token: and, IOB: O-\n",
      "Token: to, IOB: O-\n",
      "Token: understand, IOB: O-\n",
      "Token: the, IOB: O-\n",
      "Token: tradition, IOB: O-\n",
      "Token: we, IOB: O-\n",
      "Token: inherit, IOB: O-\n",
      "Token: ., IOB: O-\n",
      "Token: Why, IOB: O-\n",
      "Token: Study, IOB: O-\n",
      "Token: Philosophy, IOB: O-\n",
      "Token: ?, IOB: O-\n",
      "Token: Studying, IOB: O-\n",
      "Token: philosophy, IOB: O-\n",
      "Token: gives, IOB: O-\n",
      "Token: students, IOB: O-\n",
      "Token: the, IOB: O-\n",
      "Token: opportunity, IOB: O-\n",
      "Token: to, IOB: O-\n",
      "Token: think, IOB: O-\n",
      "Token: carefully, IOB: O-\n",
      "Token: and, IOB: O-\n",
      "Token: deeply, IOB: O-\n",
      "Token: about, IOB: O-\n",
      "Token: themselves, IOB: O-\n",
      "Token: and, IOB: O-\n",
      "Token: their, IOB: O-\n",
      "Token: place, IOB: O-\n",
      "Token: in, IOB: O-\n",
      "Token: society, IOB: O-\n",
      "Token: ., IOB: O-\n",
      "Token: A, IOB: O-\n",
      "Token: degree, IOB: O-\n",
      "Token: in, IOB: O-\n",
      "Token: philosophy, IOB: O-\n",
      "Token: involves, IOB: O-\n",
      "Token: reflection, IOB: O-\n",
      "Token: on, IOB: O-\n",
      "Token: questions, IOB: O-\n",
      "Token: such, IOB: O-\n",
      "Token: as, IOB: O-\n",
      "Token: the, IOB: O-\n",
      "Token: nature, IOB: O-\n",
      "Token: of, IOB: O-\n",
      "Token: reality, IOB: O-\n",
      "Token: ,, IOB: O-\n",
      "Token: the, IOB: O-\n",
      "Token: foundations, IOB: O-\n",
      "Token: of, IOB: O-\n",
      "Token: knowledge, IOB: O-\n",
      "Token: ,, IOB: O-\n",
      "Token: the, IOB: O-\n",
      "Token: existence, IOB: O-\n",
      "Token: of, IOB: O-\n",
      "Token: God, IOB: O-\n",
      "Token: ,, IOB: O-\n",
      "Token: and, IOB: O-\n",
      "Token: the, IOB: O-\n",
      "Token: basis, IOB: O-\n",
      "Token: of, IOB: O-\n",
      "Token: moral, IOB: O-\n",
      "Token: obligation, IOB: O-\n",
      "Token: ., IOB: O-\n",
      "Token: It, IOB: O-\n",
      "Token: encourages, IOB: O-\n",
      "Token: students, IOB: O-\n",
      "Token: to, IOB: O-\n",
      "Token: think, IOB: O-\n",
      "Token: about, IOB: O-\n",
      "Token: their, IOB: O-\n",
      "Token: obligations, IOB: O-\n",
      "Token: to, IOB: O-\n",
      "Token: their, IOB: O-\n",
      "Token: fellow, IOB: O-\n",
      "Token: human, IOB: O-\n",
      "Token: beings, IOB: O-\n",
      "Token: and, IOB: O-\n",
      "Token: the, IOB: O-\n",
      "Token: world, IOB: O-\n",
      "Token: at, IOB: O-\n",
      "Token: large, IOB: O-\n",
      "Token: ., IOB: O-\n",
      "Token: Image, IOB: O-\n",
      "Token: :, IOB: O-\n",
      "Token: Katrina, IOB: B-PERSON\n",
      "Token: Sifferd, IOB: I-PERSON\n",
      "Token: ,, IOB: O-\n",
      "Token: On, IOB: O-\n",
      "Token: the, IOB: O-\n",
      "Token: Benefits, IOB: O-\n",
      "Token: of, IOB: O-\n",
      "Token: a, IOB: O-\n",
      "Token: Philosophy, IOB: O-\n",
      "Token: Major, IOB: O-\n",
      "Token: A, IOB: O-\n",
      "Token: philosophy, IOB: O-\n",
      "Token: degree, IOB: O-\n",
      "Token: also, IOB: O-\n",
      "Token: helps, IOB: O-\n",
      "Token: students, IOB: O-\n",
      "Token: develop, IOB: O-\n",
      "Token: many, IOB: O-\n",
      "Token: of, IOB: O-\n",
      "Token: the, IOB: O-\n",
      "Token: skills, IOB: O-\n",
      "Token: necessary, IOB: O-\n",
      "Token: for, IOB: O-\n",
      "Token: success, IOB: O-\n",
      "Token: in, IOB: O-\n",
      "Token: school, IOB: O-\n",
      "Token: and, IOB: O-\n",
      "Token: beyond, IOB: O-\n",
      "Token: :, IOB: O-\n",
      "Token: logic, IOB: O-\n",
      "Token: and, IOB: O-\n",
      "Token: critical, IOB: O-\n",
      "Token: thinking, IOB: O-\n",
      "Token: ,, IOB: O-\n",
      "Token: clear, IOB: O-\n",
      "Token: argumentative, IOB: O-\n",
      "Token: writing, IOB: O-\n",
      "Token: ,, IOB: O-\n",
      "Token: careful, IOB: O-\n",
      "Token: reading, IOB: O-\n",
      "Token: and, IOB: O-\n",
      "Token: analysis, IOB: O-\n",
      "Token: of, IOB: O-\n",
      "Token: texts, IOB: O-\n",
      "Token: ,, IOB: O-\n",
      "Token: and, IOB: O-\n",
      "Token: oral, IOB: O-\n",
      "Token: argument, IOB: O-\n",
      "Token: ., IOB: O-\n",
      "Token: Philosophy, IOB: O-\n",
      "Token: majors, IOB: O-\n",
      "Token: perform, IOB: O-\n",
      "Token: very, IOB: O-\n",
      "Token: well, IOB: O-\n",
      "Token: on, IOB: O-\n",
      "Token: exams, IOB: O-\n",
      "Token: for, IOB: O-\n",
      "Token: graduate, IOB: O-\n",
      "Token: and, IOB: O-\n",
      "Token: professional, IOB: O-\n",
      "Token: school, IOB: O-\n",
      "Token: ., IOB: O-\n",
      "Token: Philosophers, IOB: O-\n",
      "Token: outscore, IOB: O-\n",
      "Token: all, IOB: O-\n",
      "Token: other, IOB: O-\n",
      "Token: majors, IOB: O-\n",
      "Token: on, IOB: O-\n",
      "Token: the, IOB: B-FAC\n",
      "Token: Graduate, IOB: I-FAC\n",
      "Token: Record, IOB: I-FAC\n",
      "Token: Exam, IOB: I-FAC\n",
      "Token: (, IOB: O-\n",
      "Token: GRE, IOB: B-ORG\n",
      "Token: ’s, IOB: O-\n",
      "Token: ), IOB: O-\n",
      "Token: and, IOB: O-\n",
      "Token: receive, IOB: O-\n",
      "Token: scores, IOB: O-\n",
      "Token: that, IOB: O-\n",
      "Token: are, IOB: O-\n",
      "Token: among, IOB: O-\n",
      "Token: the, IOB: O-\n",
      "Token: highest, IOB: O-\n",
      "Token: on, IOB: O-\n",
      "Token: the, IOB: O-\n",
      "Token: LSAT, IOB: O-\n",
      "Token: ’s, IOB: O-\n",
      "Token: ,, IOB: O-\n",
      "Token: GMAT, IOB: B-ORG\n",
      "Token: ’s, IOB: I-ORG\n",
      "Token: ,, IOB: O-\n",
      "Token: and, IOB: O-\n",
      "Token: MCAT, IOB: B-ORG\n",
      "Token: ’s, IOB: O-\n",
      "Token: ., IOB: O-\n",
      "Token: Why, IOB: O-\n",
      "Token: Study, IOB: O-\n",
      "Token: Philosophy, IOB: O-\n",
      "Token: at, IOB: O-\n",
      "Token: George, IOB: B-PERSON\n",
      "Token: Mason, IOB: I-PERSON\n",
      "Token: ?, IOB: O-\n",
      "Token: The, IOB: B-ORG\n",
      "Token: George, IOB: I-ORG\n",
      "Token: Mason, IOB: I-ORG\n",
      "Token: Department, IOB: I-ORG\n",
      "Token: of, IOB: I-ORG\n",
      "Token: Philosophy, IOB: I-ORG\n",
      "Token: has, IOB: O-\n",
      "Token: excellent, IOB: O-\n",
      "Token: full, IOB: O-\n",
      "Token: -, IOB: O-\n",
      "Token: time, IOB: O-\n",
      "Token: faculty, IOB: O-\n",
      "Token: committed, IOB: O-\n",
      "Token: to, IOB: O-\n",
      "Token: undergraduate, IOB: O-\n",
      "Token: and, IOB: O-\n",
      "Token: graduate, IOB: O-\n",
      "Token: education, IOB: O-\n",
      "Token: ., IOB: O-\n",
      "Token: The, IOB: O-\n",
      "Token: faculty, IOB: O-\n",
      "Token: reflects, IOB: O-\n",
      "Token: a, IOB: O-\n",
      "Token: wide, IOB: O-\n",
      "Token: range, IOB: O-\n",
      "Token: of, IOB: O-\n",
      "Token: philosophical, IOB: O-\n",
      "Token: interests, IOB: O-\n",
      "Token: ., IOB: O-\n",
      "Token: They, IOB: O-\n",
      "Token: work, IOB: O-\n",
      "Token: in, IOB: O-\n",
      "Token: both, IOB: O-\n",
      "Token: the, IOB: O-\n",
      "Token: analytic, IOB: O-\n",
      "Token: and, IOB: O-\n",
      "Token: Continental, IOB: B-ORG\n",
      "Token: traditions, IOB: O-\n",
      "Token: ,, IOB: O-\n",
      "Token: as, IOB: O-\n",
      "Token: well, IOB: O-\n",
      "Token: as, IOB: O-\n",
      "Token: in, IOB: O-\n",
      "Token: ethics, IOB: O-\n",
      "Token: and, IOB: O-\n",
      "Token: the, IOB: O-\n",
      "Token: history, IOB: O-\n",
      "Token: of, IOB: O-\n",
      "Token: philosophy, IOB: O-\n",
      "Token: ., IOB: O-\n",
      "Token: Junior-, IOB: B-PERSON\n",
      "Token: and, IOB: O-\n",
      "Token: senior, IOB: O-\n",
      "Token: -, IOB: O-\n",
      "Token: level, IOB: O-\n",
      "Token: courses, IOB: O-\n",
      "Token: in, IOB: O-\n",
      "Token: philosophy, IOB: O-\n",
      "Token: are, IOB: O-\n",
      "Token: small, IOB: O-\n",
      "Token: ,, IOB: O-\n",
      "Token: seminar, IOB: O-\n",
      "Token: -, IOB: O-\n",
      "Token: style, IOB: O-\n",
      "Token: courses, IOB: O-\n",
      "Token: ., IOB: O-\n",
      "Token: Most, IOB: O-\n",
      "Token: have, IOB: O-\n",
      "Token: fewer, IOB: B-CARDINAL\n",
      "Token: than, IOB: I-CARDINAL\n",
      "Token: 35, IOB: I-CARDINAL\n",
      "Token: students, IOB: O-\n",
      "Token: ., IOB: O-\n",
      "Token: This, IOB: O-\n",
      "Token: size, IOB: O-\n",
      "Token: allows, IOB: O-\n",
      "Token: for, IOB: O-\n",
      "Token: a, IOB: O-\n",
      "Token: high, IOB: O-\n",
      "Token: degree, IOB: O-\n",
      "Token: of, IOB: O-\n",
      "Token: engagement, IOB: O-\n",
      "Token: as, IOB: O-\n",
      "Token: well, IOB: O-\n",
      "Token: as, IOB: O-\n",
      "Token: an, IOB: O-\n",
      "Token: opportunity, IOB: O-\n",
      "Token: for, IOB: O-\n",
      "Token: students, IOB: O-\n",
      "Token: to, IOB: O-\n",
      "Token: work, IOB: O-\n",
      "Token: closely, IOB: O-\n",
      "Token: with, IOB: O-\n",
      "Token: their, IOB: O-\n",
      "Token: professors, IOB: O-\n",
      "Token: and, IOB: O-\n",
      "Token: develop, IOB: O-\n",
      "Token: important, IOB: O-\n",
      "Token: mentoring, IOB: O-\n",
      "Token: relationships, IOB: O-\n",
      "Token: ., IOB: O-\n",
      "Token: Why, IOB: O-\n",
      "Token: Study, IOB: O-\n",
      "Token: Philosophy, IOB: O-\n",
      "Token: ?, IOB: O-\n",
      "Token: Be, IOB: O-\n",
      "Token: Employable, IOB: O-\n",
      "Token: ,, IOB: O-\n",
      "Token: Study, IOB: O-\n",
      "Token: Philosophy, IOB: O-\n",
      "Token: Reasons, IOB: O-\n",
      "Token: to, IOB: O-\n",
      "Token: Study, IOB: O-\n",
      "Token: Philosophy, IOB: O-\n",
      "Token: Still, IOB: O-\n",
      "Token: More, IOB: O-\n",
      "Token: Reasons, IOB: O-\n",
      "Token: to, IOB: O-\n",
      "Token: Study, IOB: O-\n",
      "Token: Philosophy, IOB: O-\n",
      "Token: The, IOB: O-\n",
      "Token: Earning, IOB: O-\n",
      "Token: Power, IOB: O-\n",
      "Token: of, IOB: O-\n",
      "Token: Philosophy, IOB: O-\n",
      "Token: Majors, IOB: O-\n",
      "Token: Salary, IOB: O-\n",
      "Token: Increase, IOB: O-\n",
      "Token: by, IOB: O-\n",
      "Token: Major, IOB: B-ORG\n",
      "Token: Philosophy, IOB: I-ORG\n",
      "Token: 4400, IOB: I-ORG\n",
      "Token: University, IOB: B-PERSON\n",
      "Token: Drive, IOB: I-PERSON\n",
      "Token: ,, IOB: O-\n",
      "Token: 3F1, IOB: B-CARDINAL\n",
      "Token: Fairfax, IOB: B-GPE\n",
      "Token: ,, IOB: O-\n",
      "Token: VA, IOB: B-ORG\n",
      "Token: 22030, IOB: I-ORG\n",
      "Token: Contact, IOB: I-ORG\n",
      "Token: us, IOB: O-\n",
      "Token: Horizon, IOB: B-FAC\n",
      "Token: Hall, IOB: I-FAC\n",
      "Token: ,, IOB: O-\n",
      "Token: Room, IOB: O-\n",
      "Token: 6300, IOB: O-\n",
      "Token: +1, IOB: B-NORP\n",
      "Token: -, IOB: I-NORP\n",
      "Token: 703, IOB: I-NORP\n",
      "Token: -, IOB: O-\n",
      "Token: 993, IOB: O-\n",
      "Token: -, IOB: O-\n",
      "Token: 1290, IOB: O-\n",
      "Token: +1, IOB: O-\n",
      "Token: -, IOB: O-\n",
      "Token: 703, IOB: O-\n",
      "Token: -, IOB: O-\n",
      "Token: 993, IOB: O-\n",
      "Token: -, IOB: O-\n",
      "Token: 1297, IOB: O-\n",
      "Token: Quick, IOB: O-\n",
      "Token: Links, IOB: O-\n",
      "Token: Apply, IOB: O-\n",
      "Token: Give, IOB: O-\n",
      "Token: Request, IOB: O-\n",
      "Token: Info, IOB: O-\n",
      "Token: gmu.edu, IOB: O-\n",
      "Token: ©, IOB: O-\n",
      "Token:  , IOB: O-\n",
      "Token: Copyright, IOB: O-\n",
      "Token: 2025, IOB: B-DATE\n",
      "Token: George, IOB: B-ORG\n",
      "Token: Mason, IOB: I-ORG\n",
      "Token: University, IOB: I-ORG\n",
      "Token: ., IOB: O-\n",
      "Token: All, IOB: O-\n",
      "Token: Rights, IOB: O-\n",
      "Token: Reserved, IOB: O-\n",
      "Token: ., IOB: O-\n",
      "Token: Privacy, IOB: O-\n",
      "Token: Statement, IOB: O-\n",
      "Token: |, IOB: O-\n",
      "Token: Accessibility, IOB: O-\n"
     ]
    }
   ],
   "source": [
    "# Process the document\n",
    "doc = nlp(about_page[\"text\"])\n",
    "\n",
    "# First, let's see what entities were recognized\n",
    "print(\"Recognized entities:\")\n",
    "for ent in doc.ents:\n",
    "    print(f\"Entity: {ent.text}, Label: {ent.label_}, Span: ({ent.start}, {ent.end})\")\n",
    "\n",
    "# To get probability scores for entities, we need to access the NER pipe differently\n",
    "ner = nlp.get_pipe(\"ner\")\n",
    "\n",
    "# Let's inspect what methods and attributes are available\n",
    "print(\"\\nAvailable NER methods:\")\n",
    "for method_name in dir(ner):\n",
    "    if not method_name.startswith(\"_\"):\n",
    "        print(method_name)\n",
    "\n",
    "# Try to access scores through the model\n",
    "# This might need to be adjusted based on your spaCy version\n",
    "docs = [doc]  # Wrap in list as required by predict\n",
    "ner_scores = None\n",
    "try:\n",
    "    # Try different approaches based on spaCy version\n",
    "    if hasattr(ner, \"predict\"):\n",
    "        ner_scores = ner.predict(docs)\n",
    "    elif hasattr(ner.model, \"predict\"):\n",
    "        ner_scores = ner.model.predict(docs)\n",
    "\n",
    "    print(\"\\nNER scores type:\", type(ner_scores))\n",
    "    if ner_scores is not None:\n",
    "        print(\"NER scores structure:\", ner_scores)\n",
    "except Exception as e:\n",
    "    print(f\"Error accessing NER scores: {e}\")\n",
    "\n",
    "# As a fallback, examine the token-level entity information\n",
    "print(\"\\nToken-level entity information:\")\n",
    "for token in doc:\n",
    "    print(f\"Token: {token.text}, IOB: {token.ent_iob_}-{token.ent_type_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage:\n",
    "if __name__ == \"__main__\":\n",
    "    # Example URLs\n",
    "    urls = [\n",
    "        \"http://example1.com/about\",\n",
    "        \"http://example2.com/about\",\n",
    "        # ... more URLs ...\n",
    "    ]\n",
    "\n",
    "    # First phase: Parallel scraping\n",
    "    scraped_data = parallel_scrape(urls)\n",
    "\n",
    "    # Second phase: Location processing\n",
    "    # Note: This should be done after scraping due to memory requirements\n",
    "    results_with_locations = process_locations(scraped_data)\n",
    "\n",
    "    # Example of accessing results\n",
    "    for result in results_with_locations:\n",
    "        print(f\"URL: {result['url']}\")\n",
    "        print(f\"Locations found: {result['locations']}\")\n",
    "        print(\"---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import geograpy\n",
    "\n",
    "places = geograpy.get_geoPlace_context(url=about_page[\"url\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# a large number of items\n",
    "mydata = ['Tel Aviv']\n",
    "num_cpus = None # By default use all CPUs\n",
    "\n",
    "locations = gc.decode_parallel(about_page[\"text\"], num_cpus=num_cpus)\n",
    "print(locations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from geocode.geocode import Geocode\n",
    "\n",
    "gc = Geocode()\n",
    "gc.load()  # load geonames data\n",
    "gc.decode(\"Fairfax\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
